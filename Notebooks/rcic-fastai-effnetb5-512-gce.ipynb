{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:07.292288Z",
     "start_time": "2019-09-20T09:16:07.287742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chengjiun/Workspace/kaggle-2019Q3-cellular\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Workspace/kaggle-2019Q3-cellular/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:08.726831Z",
     "start_time": "2019-09-20T09:16:07.727330Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "BASE_DIR = '../DATA/kaggle-2019Q3-cellular/'\n",
    "\n",
    "\n",
    "def open_rcic_image(fn):\n",
    "    images = []\n",
    "    for i in range(6):\n",
    "        file_name = fn+str(i+1)+'.png'\n",
    "        im = cv2.imread(file_name)\n",
    "        if im is None: \n",
    "            print(f'file reading failed {file_name}')\n",
    "        \n",
    "        im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "        images.append(im)\n",
    "    image = np.dstack(images)\n",
    "    #print(pil2tensor(image, np.float32).shape)#.div_(255).shape)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))\n",
    "  \n",
    "class MultiChannelImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        return open_rcic_image(fn)\n",
    "    \n",
    "def image2np(image:Tensor)->np.ndarray:\n",
    "    \"Convert from torch style `image` to numpy/matplotlib style.\"\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    if res.shape[2]==1:\n",
    "        return res[...,0]  \n",
    "    elif res.shape[2]>3:\n",
    "        #print(res.shape)\n",
    "        #print(res[...,:3].shape)\n",
    "        return res[...,:3]\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "vision.image.image2np = image2np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:08.947069Z",
     "start_time": "2019-09-20T09:16:08.804840Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from joblib import load, dump\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision import models as md\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import scipy as sp\n",
    "import re\n",
    "import math\n",
    "import collections\n",
    "from functools import partial\n",
    "from torch.utils import model_zoo\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:09.629670Z",
     "start_time": "2019-09-20T09:16:09.487717Z"
    }
   },
   "outputs": [],
   "source": [
    "#original code below is from: https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This file contains helper functions for building the model and for loading model parameters.\n",
    "These helper functions are built to mirror those in the official TensorFlow implementation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Parameters for the entire model (stem, all blocks, and head)\n",
    "GlobalParams = collections.namedtuple('GlobalParams', [\n",
    "    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n",
    "    'num_classes', 'width_coefficient', 'depth_coefficient',\n",
    "    'depth_divisor', 'min_depth', 'drop_connect_rate', 'image_size'])\n",
    "\n",
    "\n",
    "# Parameters for an individual model block\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "\n",
    "# Change namedtuple defaults\n",
    "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "\n",
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def round_filters(filters, global_params):\n",
    "    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.width_coefficient\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "    divisor = global_params.depth_divisor\n",
    "    min_depth = global_params.min_depth\n",
    "    filters *= multiplier\n",
    "    min_depth = min_depth or divisor\n",
    "    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
    "    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n",
    "        new_filters += divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, global_params):\n",
    "    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.depth_coefficient\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "\n",
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_same_padding_conv2d(image_size=None):\n",
    "    \"\"\" Chooses static padding if you have specified an image size, and dynamic padding otherwise.\n",
    "        Static padding is necessary for ONNX exporting of models. \"\"\"\n",
    "    if image_size is None:\n",
    "        return Conv2dDynamicSamePadding\n",
    "    else:\n",
    "        return partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "\n",
    "class Conv2dDynamicSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a dynamic image size \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class Conv2dStaticSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n",
    "        else:\n",
    "            self.static_padding = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)\n",
    "        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "########################################################################\n",
    "############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def efficientnet_params(model_name):\n",
    "    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n",
    "    params_dict = {\n",
    "        # Coefficients:   width,depth,res,dropout\n",
    "        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
    "        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
    "        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
    "        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
    "        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
    "        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
    "        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
    "        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
    "    }\n",
    "    return params_dict[model_name]\n",
    "\n",
    "\n",
    "class BlockDecoder(object):\n",
    "    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _decode_block_string(block_string):\n",
    "        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "        assert isinstance(block_string, str)\n",
    "\n",
    "        ops = block_string.split('_')\n",
    "        options = {}\n",
    "        for op in ops:\n",
    "            splits = re.split(r'(\\d.*)', op)\n",
    "            if len(splits) >= 2:\n",
    "                key, value = splits[:2]\n",
    "                options[key] = value\n",
    "\n",
    "        # Check stride\n",
    "        assert (('s' in options and len(options['s']) == 1) or\n",
    "                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "\n",
    "        return BlockArgs(\n",
    "            kernel_size=int(options['k']),\n",
    "            num_repeat=int(options['r']),\n",
    "            input_filters=int(options['i']),\n",
    "            output_filters=int(options['o']),\n",
    "            expand_ratio=int(options['e']),\n",
    "            id_skip=('noskip' not in block_string),\n",
    "            se_ratio=float(options['se']) if 'se' in options else None,\n",
    "            stride=[int(options['s'][0])])\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_block_string(block):\n",
    "        \"\"\"Encodes a block to a string.\"\"\"\n",
    "        args = [\n",
    "            'r%d' % block.num_repeat,\n",
    "            'k%d' % block.kernel_size,\n",
    "            's%d%d' % (block.strides[0], block.strides[1]),\n",
    "            'e%s' % block.expand_ratio,\n",
    "            'i%d' % block.input_filters,\n",
    "            'o%d' % block.output_filters\n",
    "        ]\n",
    "        if 0 < block.se_ratio <= 1:\n",
    "            args.append('se%s' % block.se_ratio)\n",
    "        if block.id_skip is False:\n",
    "            args.append('noskip')\n",
    "        return '_'.join(args)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(string_list):\n",
    "        \"\"\"\n",
    "        Decodes a list of string notations to specify blocks inside the network.\n",
    "\n",
    "        :param string_list: a list of strings, each string is a notation of block\n",
    "        :return: a list of BlockArgs namedtuples of block args\n",
    "        \"\"\"\n",
    "        assert isinstance(string_list, list)\n",
    "        blocks_args = []\n",
    "        for block_string in string_list:\n",
    "            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n",
    "        return blocks_args\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(blocks_args):\n",
    "        \"\"\"\n",
    "        Encodes a list of BlockArgs to a list of strings.\n",
    "\n",
    "        :param blocks_args: a list of BlockArgs namedtuples of block args\n",
    "        :return: a list of strings, each string is a notation of block\n",
    "        \"\"\"\n",
    "        block_strings = []\n",
    "        for block in blocks_args:\n",
    "            block_strings.append(BlockDecoder._encode_block_string(block))\n",
    "        return block_strings\n",
    "\n",
    "\n",
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1000):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
    "        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "def get_model_params(model_name, override_params):\n",
    "    \"\"\" Get the block args and global params for a given model \"\"\"\n",
    "    if model_name.startswith('efficientnet'):\n",
    "        w, d, s, p = efficientnet_params(model_name)\n",
    "        # note: all models have drop connect rate = 0.2\n",
    "        blocks_args, global_params = efficientnet(\n",
    "            width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n",
    "    else:\n",
    "        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
    "    if override_params:\n",
    "        # ValueError will be raised here if override_params has fields not included in global_params.\n",
    "        global_params = global_params._replace(**override_params)\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet-b0-08094119.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet-b1-dbc7070a.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet-b2-27687264.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet-b3-c8376fa2.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet-b4-e116e8b3.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet-b5-586e6cc6.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}\n",
    "\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    if load_fc:\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        state_dict.pop('_fc.weight')\n",
    "        state_dict.pop('_fc.bias')\n",
    "        res = model.load_state_dict(state_dict, strict=False)\n",
    "        assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))\n",
    "    \n",
    "    \n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, see above\n",
    "        global_params (namedtuple): GlobalParam, see above\n",
    "\n",
    "    Attributes:\n",
    "        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n",
    "        self.id_skip = block_args.id_skip  # skip connection and drop connect\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Expansion phase\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        self._depthwise_conv = Conv2d(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n",
    "            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = self._block_args.output_filters\n",
    "        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param inputs: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
    "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
    "        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._dropout = self._global_params.dropout_rate\n",
    "        self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        if self._dropout:\n",
    "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "        x = self._fc(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))\n",
    "            \n",
    "\n",
    "# Set seed fol all\n",
    "def seed_everything(seed=1358):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:11.296628Z",
     "start_time": "2019-09-20T09:16:10.752085Z"
    },
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0229, 0.0611, 0.0396, 0.0391, 0.0219, 0.0356]), tensor([0.0271, 0.0492, 0.0219, 0.0292, 0.0183, 0.0193]))\n"
     ]
    }
   ],
   "source": [
    "#lazy calculation of stats\n",
    "pixel_stats = pd.read_csv(f'{BASE_DIR}/pixel_stats.csv')\n",
    "channel1_mean = pixel_stats.iloc[::6,:]['mean'].mean()\n",
    "channel2_mean = pixel_stats.iloc[1::6,:]['mean'].mean()\n",
    "channel3_mean = pixel_stats.iloc[2::6,:]['mean'].mean()\n",
    "channel4_mean = pixel_stats.iloc[3::6,:]['mean'].mean()\n",
    "channel5_mean = pixel_stats.iloc[4::6,:]['mean'].mean()\n",
    "channel6_mean = pixel_stats.iloc[5::6,:]['mean'].mean()\n",
    "\n",
    "\n",
    "channel1_std = pixel_stats.iloc[::6,:]['std'].mean()\n",
    "channel2_std = pixel_stats.iloc[1::6,:]['std'].mean()\n",
    "channel3_std = pixel_stats.iloc[2::6,:]['std'].mean()\n",
    "channel4_std = pixel_stats.iloc[3::6,:]['std'].mean()\n",
    "channel5_std = pixel_stats.iloc[4::6,:]['std'].mean()\n",
    "channel6_std = pixel_stats.iloc[5::6,:]['std'].mean()\n",
    "stats = (torch.Tensor([channel1_mean,channel2_mean,channel3_mean,channel4_mean,channel5_mean,channel6_mean])/255,torch.Tensor([channel1_std,channel2_std,channel3_std,channel4_std,channel5_std,channel6_std])/255)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and formatting data\n",
    "\n",
    "Here I will load the csv into the DataFrame, and create a column in the DataFrame with the path to the corresponding image (`generate_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:12.146663Z",
     "start_time": "2019-09-20T09:16:12.102366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-01_1_B08</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B08</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-01_1_B09</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B09</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-01_1_B10</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B10</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-01_1_B11</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B11</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-01_1_B12</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07    144\n",
       "5  HEPG2-01_1_B08   HEPG2-01      1  B08    503\n",
       "6  HEPG2-01_1_B09   HEPG2-01      1  B09    188\n",
       "7  HEPG2-01_1_B10   HEPG2-01      1  B10    700\n",
       "8  HEPG2-01_1_B11   HEPG2-01      1  B11   1100\n",
       "9  HEPG2-01_1_B12   HEPG2-01      1  B12    611"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:12.826451Z",
     "start_time": "2019-09-20T09:16:12.715258Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_list = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "def generate_df(train_df,sample_num=[1,2],exp=None):\n",
    "    if exp is not None:\n",
    "        train_df = train_df[train_df['exp'] == exp]\n",
    "        print(f'extract experiment: {exp}, number of train data {len(train_df)}')\n",
    "    temp_df = train_df.drop(columns=['id_code','experiment','plate','well'])\n",
    "    res_df = pd.DataFrame()\n",
    "    for s in sample_num:\n",
    "        temp_df['path'] = (train_df['experiment'].str.cat(train_df['plate'].astype(str)\n",
    "                                                .str.cat(train_df['well'],sep='/'),sep='/Plate') + '_s'+str(s) + '_w')\n",
    "        \n",
    "        temp_df = temp_df.reindex(columns=['path','sirna'])\n",
    "        if len(res_df) ==0:\n",
    "            res_df = temp_df.copy(deep=True)\n",
    "        else:\n",
    "            res_df = pd.concat([temp_df, res_df], axis=0, sort=False)\n",
    "            \n",
    "    return res_df\n",
    "\n",
    "proc_train_all_df = generate_df(train_df, sample_num=[1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:13.717508Z",
     "start_time": "2019-09-20T09:16:13.698554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01/Plate1/B03_s2_w</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01/Plate1/B04_s2_w</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01/Plate1/B05_s2_w</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01/Plate1/B06_s2_w</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01/Plate1/B07_s2_w</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-01/Plate1/B08_s2_w</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-01/Plate1/B09_s2_w</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-01/Plate1/B10_s2_w</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-01/Plate1/B11_s2_w</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-01/Plate1/B12_s2_w</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  sirna\n",
       "0  HEPG2-01/Plate1/B03_s2_w    513\n",
       "1  HEPG2-01/Plate1/B04_s2_w    840\n",
       "2  HEPG2-01/Plate1/B05_s2_w   1020\n",
       "3  HEPG2-01/Plate1/B06_s2_w    254\n",
       "4  HEPG2-01/Plate1/B07_s2_w    144\n",
       "5  HEPG2-01/Plate1/B08_s2_w    503\n",
       "6  HEPG2-01/Plate1/B09_s2_w    188\n",
       "7  HEPG2-01/Plate1/B10_s2_w    700\n",
       "8  HEPG2-01/Plate1/B11_s2_w   1100\n",
       "9  HEPG2-01/Plate1/B12_s2_w    611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_train_all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:14.360451Z",
     "start_time": "2019-09-20T09:16:14.295347Z"
    }
   },
   "outputs": [],
   "source": [
    "il = MultiChannelImageList.from_df(df=proc_train_all_df,path='../DATA/kaggle-2019Q3-cellular/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a pretrained ResNet. I have to now adjust the CNN arch to take in 6 channels as opposed to the usual 3 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:25.863389Z",
     "start_time": "2019-09-20T09:16:25.843619Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Inspired by https://github.com/wdhorton/protein-atlas-fastai/blob/master/resnet.py\"\"\"\n",
    "\n",
    "import torchvision\n",
    "RESNET_MODELS = {\n",
    "    34: torchvision.models.resnet34,\n",
    "    50: torchvision.models.resnet50,\n",
    "    101: torchvision.models.resnet101,\n",
    "    152: torchvision.models.resnet152,\n",
    "    '101x': torchvision.models.resnext101_32x8d,\n",
    "}\n",
    "\n",
    "\n",
    "def resnet_multichannel(depth=50,pretrained=True,num_classes=1108,num_channels=6):\n",
    "    model = RESNET_MODELS[depth](pretrained=pretrained)\n",
    "    w = model.conv1.weight\n",
    "    model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                           bias=False)\n",
    "    model.conv1.weight = nn.Parameter(torch.cat((w,torch.zeros(64,num_channels-3,7,7)),dim=1))\n",
    "    return model\n",
    "\n",
    "def efficientnetb4_multichannel(name='efficientnet-b4', pretrained=True, num_classes=1108, num_channels=6):\n",
    "    model = EfficientNet.from_pretrained(name, num_classes)\n",
    "    load_pretrained_weights(model,model_name=name, load_fc=False)\n",
    "    w = model._conv_stem.weight\n",
    "    model._conv_stem = Conv2dStaticSamePadding(num_channels, 48, kernel_size=3, \n",
    "                                               image_size=image_size, stride=2, padding=3)\n",
    "    model._conv_stem.weight = nn.Parameter(torch.cat((w,torch.zeros(48,num_channels-3,3,3)),dim=1))\n",
    "    return model\n",
    "\n",
    "def efficientnetb6_multichannel(name='efficientnet-b6', pretrained=True, num_classes=1108, num_channels=6):\n",
    "    model = EfficientNet.from_pretrained(name, num_classes)\n",
    "    load_pretrained_weights(model,model_name=name, load_fc=False)\n",
    "    w = model._conv_stem.weight\n",
    "    model._conv_stem = Conv2dStaticSamePadding(num_channels, 56, kernel_size=3, \n",
    "                                               image_size=image_size, stride=2, padding=3)\n",
    "    model._conv_stem.weight = nn.Parameter(torch.cat((w,torch.zeros(56,num_channels-3,3,3)),dim=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:23:38.363502Z",
     "start_time": "2019-09-20T09:23:38.241825Z"
    }
   },
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b6', 1108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:26:20.222040Z",
     "start_time": "2019-09-20T09:26:19.999603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    }
   ],
   "source": [
    "image_size=384\n",
    "def resnet34(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth=50,pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "def resnet50(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth=50,pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "def resnext101(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth='101x',pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "effnetb4 = efficientnetb4_multichannel('efficientnet-b4', pretrained=True,num_channels=6)\n",
    "\n",
    "effnetb6 = efficientnetb6_multichannel('efficientnet-b6', pretrained=True,num_channels=6)\n",
    "\n",
    "def _resnet_split(m): return (m[0][6],m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:16:32.186475Z",
     "start_time": "2019-09-20T09:16:32.168933Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"From https://www.kaggle.com/leighplt/densenet121-pytorch\"\"\"\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return torch.Tensor(np.array(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our Learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T17:12:48.484169Z",
     "start_time": "2019-09-18T17:12:48.471531Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0a31ddc7d84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia_smi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "del learn\n",
    "del data\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:20:14.996157Z",
     "start_time": "2019-09-20T09:20:14.972174Z"
    }
   },
   "outputs": [],
   "source": [
    "from optim.ranger import Ranger\n",
    "optar = partial(Ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1080Ti 9G: img size=384, efficientnet-b4, bs=16\n",
    "# 4Ti\n",
    "image_size=384\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True,\n",
    "                      max_lighting=0.2, p_lighting=0.5, \n",
    "                      max_warp=0., max_rotate=20., max_zoom=1.0)\n",
    "\n",
    "data = (MultiChannelImageList.from_df(df=proc_train_all_df,path='../DATA/kaggle-2019Q3-cellular/train/')\n",
    "        .split_by_rand_pct(0.1)\n",
    "        .label_from_df()\n",
    "        .transform(tfms,size=image_size)\n",
    "        .databunch(bs=16,num_workers=16)\n",
    "        .normalize(stats)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:26:29.352347Z",
     "start_time": "2019-09-20T09:26:27.839928Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, \n",
    "                effnetb4,\n",
    "                metrics = [accuracy], \n",
    "                model_dir='./fastaimodels').to_fp16()\n",
    "learn.model = torch.nn.DataParallel(learn.model)\n",
    "learn.path = Path('./effb6-gce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the appropriate learning rate and train the head of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T09:30:02.668151Z",
     "start_time": "2019-09-20T09:27:28.982526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 453, in forward\n    x = self.extract_features(inputs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 442, in extract_features\n    x = block(x, drop_connect_rate=drop_connect_rate)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 359, in forward\n    x = self._bn2(self._project_conv(x))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 115, in forward\n    x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\nRuntimeError: cuDNN error: CUDNN_STATUS_BAD_PARAM\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-399ce5aa3598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 453, in forward\n    x = self.extract_features(inputs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 442, in extract_features\n    x = block(x, drop_connect_rate=drop_connect_rate)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 359, in forward\n    x = self._bn2(self._project_conv(x))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-4-b87b5eb25daa>\", line 115, in forward\n    x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\nRuntimeError: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T13:21:20.976751Z",
     "start_time": "2019-09-20T09:31:03.384640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.589913</td>\n",
       "      <td>6.542411</td>\n",
       "      <td>1.122980</td>\n",
       "      <td>53:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.664667</td>\n",
       "      <td>5.661297</td>\n",
       "      <td>6.053136</td>\n",
       "      <td>49:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.721763</td>\n",
       "      <td>4.538495</td>\n",
       "      <td>15.420433</td>\n",
       "      <td>44:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.824983</td>\n",
       "      <td>3.779518</td>\n",
       "      <td>26.951521</td>\n",
       "      <td>42:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.323200</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>29.389208</td>\n",
       "      <td>39:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-3, callbacks=[SaveModelCallback(learn, every='epoch', monitor='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T13:21:28.070029Z",
     "start_time": "2019-09-20T13:21:27.369253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengjiun/Softwares/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EfficientNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/chengjiun/Softwares/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Conv2dStaticSamePadding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/chengjiun/Softwares/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MBConvBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/chengjiun/Softwares/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Identity. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "learn.save('effnetb4-stage-1')\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now unfreeze and train the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T13:39:13.430230Z",
     "start_time": "2019-09-20T13:38:00.756699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 1.10E-06\n",
      "Min loss divided by 10: 1.10E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T18:02:22.948411Z",
     "start_time": "2019-09-20T13:56:56.243819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.498375</td>\n",
       "      <td>3.784810</td>\n",
       "      <td>26.211996</td>\n",
       "      <td>41:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.812469</td>\n",
       "      <td>4.301818</td>\n",
       "      <td>20.734045</td>\n",
       "      <td>39:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.391553</td>\n",
       "      <td>3.853686</td>\n",
       "      <td>27.992331</td>\n",
       "      <td>38:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.596812</td>\n",
       "      <td>3.098163</td>\n",
       "      <td>38.537388</td>\n",
       "      <td>42:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.941670</td>\n",
       "      <td>2.755544</td>\n",
       "      <td>43.138866</td>\n",
       "      <td>41:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.650837</td>\n",
       "      <td>2.682113</td>\n",
       "      <td>44.754860</td>\n",
       "      <td>42:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(6,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T18:02:31.560796Z",
     "start_time": "2019-09-20T18:02:31.085634Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('effnetb4-stage-2')\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T05:09:36.470155Z",
     "start_time": "2019-09-21T00:59:21.188867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.540594</td>\n",
       "      <td>2.709393</td>\n",
       "      <td>44.480965</td>\n",
       "      <td>47:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.530679</td>\n",
       "      <td>2.659583</td>\n",
       "      <td>45.768284</td>\n",
       "      <td>49:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.421624</td>\n",
       "      <td>2.683297</td>\n",
       "      <td>45.412216</td>\n",
       "      <td>50:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>2.647002</td>\n",
       "      <td>46.316078</td>\n",
       "      <td>51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.262001</td>\n",
       "      <td>2.684255</td>\n",
       "      <td>45.877842</td>\n",
       "      <td>51:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T02:57:14.513892Z",
     "start_time": "2019-09-22T02:57:12.367594Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('effnetb4-stage-2')\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T20:53:23.200975Z",
     "start_time": "2019-09-21T16:28:21.522769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.169876</td>\n",
       "      <td>2.618689</td>\n",
       "      <td>47.137772</td>\n",
       "      <td>52:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.172119</td>\n",
       "      <td>2.661130</td>\n",
       "      <td>46.206520</td>\n",
       "      <td>50:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.243145</td>\n",
       "      <td>2.644564</td>\n",
       "      <td>46.726925</td>\n",
       "      <td>53:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.235656</td>\n",
       "      <td>2.649640</td>\n",
       "      <td>46.562584</td>\n",
       "      <td>54:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.185921</td>\n",
       "      <td>2.644634</td>\n",
       "      <td>46.617367</td>\n",
       "      <td>53:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T02:57:54.731388Z",
     "start_time": "2019-09-22T02:57:54.441339Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "proc_test_df = generate_df(test_df.copy(), sample_num=1)\n",
    "data_test = MultiChannelImageList.from_df(df=proc_test_df,path=f'{BASE_DIR}/test/')\n",
    "learn.data.add_test(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T03:28:21.545769Z",
     "start_time": "2019-09-22T02:58:25.169741Z"
    }
   },
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)\n",
    "preds_ = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T03:59:56.480866Z",
     "start_time": "2019-09-22T03:30:24.321117Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_test_df = generate_df(test_df.copy(), sample_num=2)\n",
    "data_test = MultiChannelImageList.from_df(df=proc_test_df,path=f'{BASE_DIR}/test/')\n",
    "learn.data.add_test(data_test)\n",
    "preds2, _ = learn.get_preds(DatasetType.Test)\n",
    "preds2_ = preds2.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:18:13.579272Z",
     "start_time": "2019-09-22T04:18:13.537561Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_mean = (preds + preds2)/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the sample submission file and load it with our predictions to create a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:18:25.228771Z",
     "start_time": "2019-09-22T04:18:25.180053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-08_1_B08</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-08_1_B09</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-08_1_B10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-08_1_B11</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-08_1_B12</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code  sirna\n",
       "0  HEPG2-08_1_B03     52\n",
       "1  HEPG2-08_1_B04      7\n",
       "2  HEPG2-08_1_B05     92\n",
       "3  HEPG2-08_1_B06    312\n",
       "4  HEPG2-08_1_B07    135\n",
       "5  HEPG2-08_1_B08    981\n",
       "6  HEPG2-08_1_B09    118\n",
       "7  HEPG2-08_1_B10      0\n",
       "8  HEPG2-08_1_B11    520\n",
       "9  HEPG2-08_1_B12   1090"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "submission_df.sirna = preds_.numpy().astype(int)\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:18:34.869346Z",
     "start_time": "2019-09-22T04:18:34.709565Z"
    }
   },
   "outputs": [],
   "source": [
    "## local CV: 0.46 single site\n",
    "submission_df.to_csv('submission-effB4-384-singlesite.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:18:46.466285Z",
     "start_time": "2019-09-22T04:18:46.443324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-08_1_B08</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-08_1_B09</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-08_1_B10</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-08_1_B11</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-08_1_B12</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code  sirna\n",
       "0  HEPG2-08_1_B03    468\n",
       "1  HEPG2-08_1_B04      7\n",
       "2  HEPG2-08_1_B05   1091\n",
       "3  HEPG2-08_1_B06    908\n",
       "4  HEPG2-08_1_B07    135\n",
       "5  HEPG2-08_1_B08    981\n",
       "6  HEPG2-08_1_B09    118\n",
       "7  HEPG2-08_1_B10    638\n",
       "8  HEPG2-08_1_B11    807\n",
       "9  HEPG2-08_1_B12    778"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_mean_ = preds_mean.argmax(dim=-1)\n",
    "submission_df['sirna'] = preds_mean_.numpy().astype(int)\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:18:57.497296Z",
     "start_time": "2019-09-22T04:18:57.420323Z"
    }
   },
   "outputs": [],
   "source": [
    "## local CV: 0.46\n",
    "submission_df.to_csv('submission-effB4-384-doublesite.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T03:28:33.103863Z",
     "start_time": "2019-09-22T03:28:33.088975Z"
    }
   },
   "outputs": [],
   "source": [
    "## self-boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:23:15.692610Z",
     "start_time": "2019-09-22T04:23:15.670180Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = submission_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:29:41.458550Z",
     "start_time": "2019-09-22T04:29:41.436181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 3, 1],\n",
       "       [1, 3, 4, 2],\n",
       "       [2, 4, 1, 3],\n",
       "       [1, 3, 4, 2],\n",
       "       [3, 1, 2, 4],\n",
       "       [1, 3, 4, 2],\n",
       "       [1, 3, 4, 2],\n",
       "       [2, 4, 1, 3],\n",
       "       [1, 3, 4, 2],\n",
       "       [4, 2, 3, 1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_groups[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:23:30.316644Z",
     "start_time": "2019-09-22T04:23:28.174044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 0 0 0 2 2 3 0 0 3 1 0 0 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "plate_groups = np.zeros((1108,4), int)\n",
    "for sirna in range(1108):\n",
    "    grp = train_df.loc[train_df.sirna==sirna,:].plate.value_counts().index.values\n",
    "    assert len(grp) == 3\n",
    "    plate_groups[sirna,0:3] = grp\n",
    "    plate_groups[sirna,3] = 10 - grp.sum()\n",
    "    \n",
    "\n",
    "\n",
    "all_test_exp = test_df.experiment.unique()\n",
    "group_plate_probs = np.zeros((len(all_test_exp),4))\n",
    "for idx in range(len(all_test_exp)):\n",
    "    preds = sub_df.loc[test_df.experiment == all_test_exp[idx],'sirna'].values\n",
    "    pp_mult = np.zeros((len(preds),1108))\n",
    "    pp_mult[range(len(preds)),preds] = 1\n",
    "    \n",
    "    sub_test = test_df.loc[test_df.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    \n",
    "    for j in range(4):\n",
    "        mask = np.repeat(plate_groups[np.newaxis, :, j], len(pp_mult), axis=0) == \\\n",
    "               np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "        \n",
    "        group_plate_probs[idx,j] = np.array(pp_mult)[mask].sum()/len(pp_mult)\n",
    "\n",
    "exp_to_group = group_plate_probs.argmax(1)\n",
    "print(exp_to_group)\n",
    "\n",
    "\n",
    "def select_plate_group(pp_mult, idx, \n",
    "                       test_df=test_df, all_test_exp=all_test_exp, plate_groups=plate_groups,\n",
    "                       exp_to_group=exp_to_group):\n",
    "    sub_test = test_df.loc[test_df.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    mask = np.repeat(plate_groups[np.newaxis, :, exp_to_group[idx]], len(pp_mult), axis=0) != \\\n",
    "           np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "    pp_mult[mask] = 0\n",
    "    return pp_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:23:49.834326Z",
     "start_time": "2019-09-22T04:23:49.570276Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(len(all_test_exp)):\n",
    "    #print('Experiment', idx)\n",
    "    indices = (test_df.experiment == all_test_exp[idx])\n",
    "    \n",
    "    preds_slice = preds_mean.numpy()[indices,:].copy()\n",
    "    \n",
    "    preds_slice = select_plate_group(preds_slice, idx, \n",
    "                                     test_df=test_df, all_test_exp=all_test_exp, plate_groups=plate_groups,\n",
    "                                     exp_to_group=exp_to_group)\n",
    "    sub_df.loc[indices,'sirna'] = preds_slice.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-22T04:24:04.291873Z",
     "start_time": "2019-09-22T04:24:04.274399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['sirna2'] = sub_df['sirna']\n",
    "(submission_df['sirna2'] != submission_df['sirna']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission-resnet101-doublesite-boost.csv',index=False)\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
